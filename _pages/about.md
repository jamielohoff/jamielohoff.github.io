---
title: About Me
permalink: /about/
layout: single
author_profile: true
---


**Upbringing and age**: I was born on March 11th, 1996 in Illertissen, Bavaria and grew up in the suburbs of Stuttgart.<br>
**Marital status**: Married to the most beautiful woman in the world (10/10, would do again).<br>
**Education**: Studied Physics in Stuttgart and Heidelberg (BS, MS) .<br>
**Occupation**: Doing a PhD in Neuromorphic Computing and Artificial Intelligence at RWTH Aachen and Jülich Research Center. It's a lot of fun!<br>
**Dream Jobs**: Staff Scientist, Professor (because lecturing), CEO/Founder of **small** (5-10 ppl.) company


# The Scientific Me
I am yet another physicist who left the field because auf the Neuroscience and AI hype. 
This however does not mean that I have given up on all the physics and math; quite the contrary actually.
What intrigues me about Neuroscience and AI is the lack of good foundational theory that allows us to truly understand what makes animals, humans and machines intelligent.
Is intelligence an emergent property that results from scaling up? Is it the connectome of the network that matters? Or is it the computational substrate itself?<br>
My guess would be that it is a superposition of all these effects, but we don't know yet how to combine these ingredients in a systematic way.
I believe that insights from mathematics, physics, control theory and electrical engineering can be of help there.
I am particularly interested in applying methods from Statistical Physics and Differential Geometry to these problems an see how far I can get with that.
Why? No specific reason. I just like the ideas and the math and hope to have fun along the way.
If I had to justify it though, I would probably give an answer similar to:<br>

> Statistical physics is the study of large-scale systems composed of microscopic entities to understand their macroscopic, collective behavior.
It is thus a good choice for studing whether intelligence is an emergent property of ensembles of neurons.

<br>

>Differential Geometry enables one to study optimization. In my view learning and optimization are very similar; sometimes even the same, e.g. supervised learning.
Therefore it is possibly a good framework to think about learning. Maybe.<br>

Apart from these very theoretical considerations, I am also a big fan of actually building cool and useful things, which is also why I want to understand Neuroscience and AI better in the first place. I am convinced that we can only build cooler and better stuff if we really understand what we are doing.
<br><br>

**Neuroscience-inspired** stuff that I had the pleasure to work with:
- Event-based cameras that work like the human retina
- Various SNNs with event-based and frame-based datasets
- Spiking neural network accelerators aka. silicon brains (BrainScalesS, Speck, DynapCNN)
- BPTT, RTRL, E-Prop, Event-Prop and all the other famous learning rules

**Deep Learning** stuff that I have enjoyed working with so far:
- Transformers (who hasn't though...)
- Reinforcement Learning, in particular PPO and AlphaZero
- Neural Differential Equations, although it is just the Pontryagin Principle from Control Theory at work
- All the default AI crap like CNNs, RNNs, LSTMs, MLPs, ResNets

**Physics** stuff that I came across which is not in the default curriculum:
- Cosmology, Quintessence models, Brans-Dicke, Sting Theory
- Infrared telescopy, especially the trajectory of the star S2 orbiting the Milkyway Central Blackhole
- Quantum Field Theory, although the Renormalization of QED is still kind of a fucked-up thing to me, Symmetry-breaking and Goldstone Bosons are a cool theory
- Topological Edge States, Topological Insulators, Topological QFT, but only the basics
- Differential Geometry and Topology (my favorite math topics, only non-standard for a physicist)
- Quantum Information Theory, but never used a Quantum Computer

Stuff that is on my **To-Learn** list:
- Physical Computing, e.g. memristors, coupled systems of spins, computing with lasers and non-linear optics etc.
- Neuroscience, especially wet-ware computing, i.e. use actual biological substrates to do stuff (I am dreaming of a GPU that literally lives inside my PC)
- Brain-Machine Interfaces, remote-controlling of prosthetics
- Robotics, in particular drones and sunmarines
- Compute-in-Memory Architectures

**CV**: <br>

**Favorite Scientists** (It is better to have idols that are already dead because they cannot dissapoint you anymore than they already did):
1.) Kurt Gödel: He is king, for obvious reasons...
2.) Wolfgang Pauli: Party hard, think harder...
3.) Richard Feynman: Only as a scientist and lecturer, not as a human being (his views on women disgust me...)
 

# The Interesting Me
**Controversial Opinions**
- Jax >> PyTorch
- Linx > Mac >> Windows
- Children should learn how to code in school and there should be more focus on statistics and rational decision-making should be part of the curriculum as well
- Teachers/Professors are very much responsible for students liking (or disliking) a particular field
- AI has already taken over the world, but much more subtle than most people think. This is even worse than an all out "Matrix" or "Terminator" style war. It is going to be a long way until we have self-aware machines with their own free will (if it exists...)

  
**Hobbies**:
- Hiking, Bouldering and Rock Climbing
- Everying that goes fast and is dangerous, e.g. cars, motorcycles, skiing, mountain biking
- Woodworking (see Other Projects)
- Guitar and music, especially Rock (Guns'n'Roses), Jazz (Herbie Hancock, Oscar Petterson) and Classical Music (Beethoven)
